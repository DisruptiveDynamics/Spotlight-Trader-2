Perfect â€” yes, youâ€™re right. Weâ€™ve reached Prompt 16, the final master prompt in your SpotLight Trader build sequence.
This closes the loop: it locks in your Safari/iOS audio reliability, AudioWorklet low-latency pipeline, and final barge-in optimization, completing the AI Voice Coach + real-time chart ecosystem.

Hereâ€™s the full, clean copy-and-paste version for Replit ðŸ‘‡

â¸»

Replit Agent Work Order â€” Prompt 16 (Final Master Step)

ðŸŽ¯ Safari AudioContext Gesture Unlock + AudioWorklet Upgrade + Final Voice Coach Tuning

Goal:
Make the Voice Coach fully production-ready across iOS, macOS, and desktop browsers with flawless mic activation, barge-in control, and sub-100 ms latency.
This step finalizes the Voice Assistantâ€™s pipeline so it works like Siri/ChatGPT Voice in any browser environment.

â¸»

ðŸ§  1 Â· AudioContext Gesture Unlock (Safari / iPad Fix)

File: client/src/services/AudioManager.ts

export async function ensureAudioUnlocked() {
  try {
    const ctx = new (window.AudioContext || (window as any).webkitAudioContext)();
    if (ctx.state === 'suspended') {
      await ctx.resume();
    }
    const buffer = ctx.createBuffer(1, 1, 22050);
    const source = ctx.createBufferSource();
    source.buffer = buffer;
    source.connect(ctx.destination);
    source.start(0);
    await new Promise(r => setTimeout(r, 50));
    return ctx;
  } catch (err) {
    console.warn('Audio unlock failed', err);
    return null;
  }
}

Call ensureAudioUnlocked() from the bubble onClick gesture before creating any mic or playback nodes.

â¸»

âš™ï¸ 2 Â· Switch to AudioWorklet for Low-Latency Capture

Files: client/src/services/AudioCapture.ts, client/src/workers/audioWorkletProcessor.js

A) AudioWorklet Registration

export async function startMicWorklet(ctx: AudioContext, onChunk: (pcm: Int16Array) => void) {
  await ctx.audioWorklet.addModule('/worklets/micProcessor.js');
  const node = new AudioWorkletNode(ctx, 'mic-processor');
  node.port.onmessage = (e) => {
    if (e.data?.pcm) onChunk(new Int16Array(e.data.pcm));
  };
  const stream = await navigator.mediaDevices.getUserMedia({
    audio: { echoCancellation: true, noiseSuppression: true, channelCount: 1, sampleRate: 16000 }
  });
  const src = ctx.createMediaStreamSource(stream);
  src.connect(node);
  node.connect(ctx.destination);
  return node;
}

B) Worklet Processor

File: public/worklets/micProcessor.js

class MicProcessor extends AudioWorkletProcessor {
  process(inputs) {
    const input = inputs[0];
    if (!input || !input[0]) return true;
    const samples = input[0];
    const pcm16 = new Int16Array(samples.length);
    for (let i = 0; i < samples.length; i++) {
      pcm16[i] = Math.max(-1, Math.min(1, samples[i])) * 0x7fff;
    }
    this.port.postMessage({ pcm: pcm16.buffer }, [pcm16.buffer]);
    return true;
  }
}
registerProcessor('mic-processor', MicProcessor);


â¸»

ðŸ—£ï¸ 3 Â· Barge-In Enhancement (Fast Interrupt)

File: client/src/services/VoiceCoach.ts

export function handleBargeIn(realtime, playbackNode, gainNode) {
  try {
    realtime.send(JSON.stringify({ type: 'response.cancel' }));
  } catch {}
  if (gainNode?.gain) gainNode.gain.setValueAtTime(0, playbackNode.context.currentTime);
  playbackNode?.stop?.();
}

Call handleBargeIn() whenever VAD detects user speech while coach is speaking.

â¸»

ðŸ”„ 4 Â· Frame Coalescing & Backpressure
	â€¢	Bundle audio frames (20â€“40 ms each) before send.
	â€¢	If sendQueue.length > 8, drop oldest frame.
	â€¢	Keeps latency < 100 ms under poor networks.

â¸»

ðŸ’¤ 5 Â· Idle Sleep / Wake Revalidation

File: client/src/app/idleDetector.ts

let idleTimer;
function resetIdle() {
  clearTimeout(idleTimer);
  idleTimer = setTimeout(() => {
    voiceCoach.stopListening();
    voiceCoach.closeConnection();
    console.log('AI Coach asleep due to inactivity');
  }, 30 * 60 * 1000); // 30 minutes
}
window.addEventListener('mousemove', resetIdle);
window.addEventListener('keydown', resetIdle);

When the user interacts again â†’ reopen Realtime connection + AudioContext.

â¸»

âœ… Definition of Done
	â€¢	Mic/Audio works on Safari/iPad with 1-tap unlock.
	â€¢	AudioWorklet path replaces ScriptProcessorNode for lower latency.
	â€¢	Barge-in interrupts instantly (< 250 ms end-to-silence).
	â€¢	Stable across reconnects and idle sleep/wake.
	â€¢	No console errors: â€œcontext suspendedâ€, â€œscriptProcessor deprecatedâ€, or â€œsession.update missingâ€.

â¸»

ðŸ’» After Replit Finishes

Run:

npm run build
npm run dev

Then test:
	1.	Tap bubble on Safari â†’ voice unlock works.
	2.	Speak â†’ assistant responds.
	3.	Talk over assistant â†’ immediate barge-in.
	4.	Idle 30 min â†’ coach sleeps; tap bubble â†’ wakes cleanly.

â¸»

ðŸ Congratulations â€” This is Prompt 16, the final one.

After this step your SpotLight Trader platform will have:
	â€¢	ThinkorSwim-grade real-time charting
	â€¢	A fully functional, cross-platform Voice Coach
	â€¢	Stable auth and reconnect logic
	â€¢	Enterprise-quality architecture ready for scale ðŸš€